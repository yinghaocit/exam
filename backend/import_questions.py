import os
from dotenv import load_dotenv

load_dotenv()

import json
import httpx
import asyncio
from tenacity import retry, stop_after_attempt, wait_fixed, retry_if_exception_type
from more_itertools import chunked
from tqdm.asyncio import tqdm_asyncio
from tqdm import tqdm  # ç”¨äº tqdm.write()

API_URL = os.getenv("BASE_URL", "http://localhost:8000") + "/questions"
INPUT_FILE = "questions.json"
FAILED_FILE = "failed.json"
MAX_CONCURRENT_REQUESTS = 10
BATCH_SLEEP_INTERVAL = 0.5


def convert_to_api_format(question):
    q_type = 2 if len(question["correct_answer"]) > 1 else 1
    answers = [
        {"content": val, "is_correct": key in question["correct_answer"]}
        for key, val in question["options"].items()
    ]
    return {
        "original_number": question['number'],
        "type": q_type,
        "question": question["question"],
        "explanation": question["explanation"],
        "answers": answers
    }


@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), retry=retry_if_exception_type(httpx.RequestError))
async def upload_question(client, semaphore, question):
    async with semaphore:
        payload = convert_to_api_format(question)
        try:
            response = await client.post(API_URL, json=payload)
            if response.status_code == 200:
                tqdm.write(f"[âœ“] ç¬¬ {question['number']} é¢˜ä¸Šä¼ æˆåŠŸ")
                return True
            else:
                tqdm.write(f"[Ã—] ç¬¬ {question['number']} é¢˜ä¸Šä¼ å¤±è´¥: {response.status_code} {response.text}")
                return False
        except Exception as e:
            tqdm.write(f"[Ã—] ç¬¬ {question['number']} é¢˜è¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            raise  # è§¦å‘é‡è¯•


async def upload_all():
    tqdm.write("å¼€å§‹ä¸Šä¼ æ‰€æœ‰é¢˜ç›®...")
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        questions = json.load(f)

    failed_questions = []
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)

    limits = httpx.Limits(
        max_connections=MAX_CONCURRENT_REQUESTS * 2,
        max_keepalive_connections=MAX_CONCURRENT_REQUESTS
    )

    async with httpx.AsyncClient(timeout=60.0, limits=limits) as client:
        success_count = 0
        for batch_index, batch in enumerate(chunked(questions, MAX_CONCURRENT_REQUESTS), start=1):
            tqdm.write(f"\nğŸš€ æ­£åœ¨ä¸Šä¼ ç¬¬ {batch_index} æ‰¹é¢˜ç›®ï¼Œå…± {len(batch)} é“é¢˜")
            tasks = [upload_question(client, semaphore, q) for q in batch]
            results = await tqdm_asyncio.gather(*tasks, desc="ä¸Šä¼ ä¸­", ncols=80)
            for q, result in zip(batch, results):
                if not result:
                    failed_questions.append(q)
            success_count += sum(results)
            await asyncio.sleep(BATCH_SLEEP_INTERVAL)

    tqdm.write(f"\nâœ… ä¸Šä¼ å®Œæˆï¼šæˆåŠŸ {success_count} / å…± {len(questions)} é“é¢˜")
    if failed_questions:
        with open(FAILED_FILE, "w", encoding="utf-8") as f:
            json.dump(failed_questions, f, ensure_ascii=False, indent=2)
        tqdm.write(f"âš ï¸ å¤±è´¥çš„é¢˜ç›®å·²ä¿å­˜åˆ° {FAILED_FILE}ï¼Œå¯ä»¥ç¨åé‡è¯•ã€‚")


if __name__ == "__main__":
    asyncio.run(upload_all())
